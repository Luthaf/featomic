{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "In a new conda environment, install the following packages in the following\n",
    "order:\n",
    "\n",
    "1. `pip install git+https://github.com/luthaf/rascaline.git@clebsch_gordan`\n",
    "2. `pip install git+https://github.com/lab-cosmo/metatensor.git`\n",
    "3. Optional but nice: `pip install chemiscope` (allows you to visualize the\n",
    "   dataset)\n",
    "\n",
    "\n",
    "Also required: `ase` and `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ase.io\n",
    "import numpy as np\n",
    "\n",
    "import chemiscope\n",
    "import metatensor\n",
    "from metatensor import Labels, TensorBlock, TensorMap\n",
    "\n",
    "import rascaline\n",
    "import clebsch_gordan\n",
    "# from rascaline.utils import clebsch_gordan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read frames and visualize with `chemiscope`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read(\"combined_magres_spherical.xyz\", \":\")\n",
    "chemiscope.show(frames, mode=\"structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert target property to `metatensor` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a TensorMap for each frame, then combine them into a single\n",
    "# TensorMap at the end\n",
    "structure_tms = []\n",
    "for frame_i, frame in enumerate(frames):\n",
    "    # Get the number of atoms in the frame\n",
    "    n_atoms = frame.get_global_number_of_atoms()\n",
    "\n",
    "    # Store the target data by l value and chemical species (i.e. atomic number)\n",
    "    data_dict = {}\n",
    "    for atom_i, atomic_number in enumerate(frame.get_atomic_numbers()):\n",
    "        for l, data in zip(\n",
    "            [0, 2], [frames[0].arrays[\"efg_L0\"], frames[0].arrays[\"efg_L2\"]]\n",
    "        ):\n",
    "            key = (l, atomic_number)\n",
    "            data_arr = data[atom_i]\n",
    "            if isinstance(data_arr, float):\n",
    "                data_arr = np.array([data_arr])\n",
    "            # Store the data array\n",
    "            if data_dict.get(key) is None:\n",
    "                data_dict[key] = {atom_i: data_arr}\n",
    "            else:\n",
    "                data_dict[key][atom_i] = data_arr\n",
    "\n",
    "    # Build the keys of the resulting TensorMap\n",
    "    keys = Labels(\n",
    "        names=[\"spherical_harmonics_l\", \"species_center\"],\n",
    "        values=np.array([[l, species_center] for l, species_center in data_dict.keys()]),\n",
    "    )\n",
    "\n",
    "    # Construct the TensorMap blocks for each of these keys\n",
    "    blocks = []\n",
    "    for l, species_center in keys.values:\n",
    "        # Retrive the raw block data\n",
    "        data = data_dict[(l, species_center)]\n",
    "\n",
    "        # Get a list of sorted samples (i.e. atom indices) for the block \n",
    "        n_atoms_block = len(data)\n",
    "        ordered_atom_idxs = sorted(data.keys())\n",
    "\n",
    "        # Sort the raw block data\n",
    "        block_data = np.array([data[atom_i] for atom_i in ordered_atom_idxs]).reshape(\n",
    "            n_atoms_block, 2 * l + 1, 1\n",
    "        )\n",
    "\n",
    "        # Construct a TensorBlock, where the raw data is labelled with metadata\n",
    "        # Note here that we keep track of the structure index - this is\n",
    "        # important for later when we join the TensorMaps\n",
    "        block = TensorBlock(\n",
    "            values=block_data,\n",
    "            samples=Labels(\n",
    "                names=[\"structure\", \"center\"],\n",
    "                values=np.array([[frame_i, atom_i] for atom_i in ordered_atom_idxs]),\n",
    "            ),\n",
    "            components=[\n",
    "                Labels(\n",
    "                    names=[\"spherical_harmonics_m\"],\n",
    "                    values=np.arange(-l, l + 1).reshape(-1, 1),\n",
    "                )\n",
    "            ],\n",
    "            properties=Labels(\n",
    "                names=[\"efg\"],\n",
    "                values=np.array([[0]]).reshape(-1, 1),\n",
    "            ),\n",
    "        )\n",
    "        # Store the block\n",
    "        blocks.append(block)\n",
    "\n",
    "    # Construct a TensorMap for this structure from the keys and blocks\n",
    "    structure_tms.append(TensorMap(keys=keys, blocks=blocks))\n",
    "\n",
    "# Now join the stucture-based TensorMaps into a single TensorMap. We want to\n",
    "# join along the \"samples\" axis\n",
    "efg = metatensor.join(structure_tms, axis=\"samples\", remove_tensor_name=True)\n",
    "\n",
    "# Save the TensorMap to file\n",
    "metatensor.save(\"efg.npz\", efg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorMap is comprised of 6 blocks, each corresponding to a different\n",
    "combination of l channel and chemical species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efg.keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick out all the invariant blocks using `TensorMap.blocks()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efg.blocks(spherical_harmonics_l=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just a single block using `TensorMap.block()`. i.e. for l = 2, titanium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = efg.block(spherical_harmonics_l=2, species_center=22)\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each TensorBlock is a tensor of values, wrapped with metadata. The \"samples\" are\n",
    "always the first axis, the \"properties\" always the last axis, and all intermediate\n",
    "axes are \"components\". Here the samples track the atom indices and which\n",
    "structure they belong to. The components track the symmetry of the target\n",
    "property. In this case we're representing the data in the spherical basis, so\n",
    "there is a single component axis that tracks the $m$ component of the\n",
    "irreducible spherical component (ISC) vector. As we only have a single property\n",
    "per atom the properties axis has size one, and is just labelled with \"efg\" here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data is stored in this case as a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(block.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also convert, for instance, to a torch backend. (Commented out in\n",
    "case you don't have torch installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# efg_torch = metatensor.to(efg, backend=\"torch\")\n",
    "# type(efg_torch.block(0).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate $\\lambda$-SOAP descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to generate a $\\nu=1$ order spherical expansion (an\n",
    "atom-centered density correlation) using the `SphericalExpansion` calculator in\n",
    "rascaline. From there we combine it with itself using Clebsch-Gordan iterations\n",
    "to generate the $\\nu=2$ order descriptor, i.e. $\\lambda$-SOAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for generating the rascaline SphericalExpansion\n",
    "rascal_hypers = {\n",
    "    \"cutoff\": 3.0,  # Angstrom\n",
    "    \"max_radial\": 6,  # Exclusive\n",
    "    \"max_angular\": 5,  # Inclusive\n",
    "    \"atomic_gaussian_width\": 0.2,\n",
    "    \"radial_basis\": {\"Gto\": {}},\n",
    "    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n",
    "    \"center_atom_weight\": 1.0,\n",
    "}\n",
    "calculator = rascaline.SphericalExpansion(**rascal_hypers)\n",
    "nu_1_tensor = calculator.compute(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target lambda channels - we only want invariant l=0 and l=2 channels to\n",
    "# match the target property EFG\n",
    "angular_selection = [0, 2]\n",
    "\n",
    "# Now generate the lambda-SOAP vector\n",
    "lsoap = clebsch_gordan.lambda_soap_vector(\n",
    "    nu_1_tensor=nu_1_tensor,\n",
    "    angular_selection=angular_selection,\n",
    "    parity_selection=+1,\n",
    ")\n",
    "\n",
    "# Save\n",
    "metatensor.save(\"lsoap.npz\", lsoap)\n",
    "\n",
    "lsoap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on the argument `angular_cutoff`, which can be set but isn't used\n",
    "above. This sets the maximum intermediate value of lambda used when performing\n",
    "CG iterations. The maximum value corresponding to non-zero combinations is given\n",
    "by `target_body_order * rascal_hypers[\"max_angular\"]`.\n",
    "\n",
    "`target_body_order` is the target body-order of the descriptor. When using the\n",
    "publci function `clebsch_gordan.lambda_soap_vector` as above,\n",
    "`target_body_order` is by definition 2 so the specifying this isn't required.\n",
    "For generating descriptors of higher body order, using the public function\n",
    "`clebsch_gordan.combine_single_center_to_body_order`, this argumetn can be\n",
    "specified. \n",
    "\n",
    "In some cases, particular for combinations to high body order (beyond\n",
    "lambda-SOAP), combining at each iteration to the theoretical maximum can lead to\n",
    "memory blow-up, so the `angular_cutoff` needs to be tailored in each case.\n",
    "Setting this cutoff to less than theoretical maximum will lead to some\n",
    "information loss. In the above function call I didn't specify `angular_cutoff`\n",
    "so it just takes the maximum by default. \n",
    "\n",
    "The same logic also applies to the use of `angular_selection` and\n",
    "`parity_selection`. Applying selection filters on intermediate iterations (i.e.\n",
    "not the final one) can lead to some information loss, but reduce memory\n",
    "consumption particularly at high body orders. `angular_cutoff` is essentially a\n",
    "way of applying a global maximum cutoff to all iterations, whereas\n",
    "`angular_selection` allows control of which specific angular channels are\n",
    "constructed at each iteration. In our case, we only perform one iteration to\n",
    "form our lambda-SOAP descriptor. As there are techincally no intermediate\n",
    "iterations (only the case for num. iterations > 1), applying angular and parity\n",
    "selections on the final (and only) iteration results in no information loss.\n",
    "\n",
    "Inspect the $\\lambda$-SOAP descriptor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap.block(spherical_harmonics_l=2, species_center=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples and components metadata are equivalent when compared to\n",
    "the corresponding block of the EFG tensor, but the properties aren't, as the\n",
    "relationship from descriptor properties -> target properties is the thing we wa\n",
    "machine learn.\n",
    "\n",
    "It is important that all other metadata, except for the properties of each\n",
    "block, agrees. More specifically, there should be a one-to-one mapping of\n",
    "blocks, indexed by the same set of keys. For each of these blocks, the samples\n",
    "and components should be the same and in the same order.\n",
    "\n",
    "This can be checked with the following function in `metatensor`. Here we toggle a\n",
    "check for samples and components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metatensor.equal_metadata(lsoap, efg, check=[\"samples\", \"components\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But checking for properties too fails the test, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metatensor.equal_metadata(lsoap, efg, check=[\"samples\", \"components\", \"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are loads of other operations and convenience functions for checking and\n",
    "manipulating both the data and metadata of TensorMaps. Check out the\n",
    "[docs](https://lab-cosmo.github.io/metatensor/latest/) for more info! If there's\n",
    "an operation we don't have but you think would be useful, please [open an\n",
    "issue](https://github.com/lab-cosmo/metatensor/issues/new/choose) :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
